{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "from xarrayms import xds_from_ms, xds_from_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from the Measurement Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful readonly open of default-locked table 1491291289.1GC.ms: 26 columns, 129480 rows\n"
     ]
    }
   ],
   "source": [
    "xds = list(xds_from_ms(\"1491291289.1GC.ms\", columns=[\"ANTENNA1\", \"ANTENNA2\"], \n",
    "                       group_cols=[], index_cols=[], chunks={\"row\": 1e9}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access Individual elements in xds variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for loop look to loop through all columns at a later stage\n",
    "\n",
    "Find the unique baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xds[0]\n",
    "assert ds.ANTENNA1.dtype == ds.ANTENNA2.dtype == np.int32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack antenna1 and antenna2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129480, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl = da.stack([ds.ANTENNA1.data, ds.ANTENNA2.data], axis=1)\n",
    "bl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert array to dtype int64 from int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129480, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl = bl.rechunk(-1,2).view(np.int64)\n",
    "bl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get unique values (baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubl = da.unique(bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful readonly open of user-locked table 1491291289.1GC.ms: 26 columns, 129480 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ubl = da.compute(ubl)[0].view(np.int32).reshape(-1,2)\n",
    "ubl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful readonly open of default-locked table 1491291289.1GC.ms: 26 columns, 129480 rows\n"
     ]
    }
   ],
   "source": [
    "xds = list(xds_from_ms(\"1491291289.1GC.ms\", columns=[\"TIME\", \"ANTENNA1\", \"ANTENNA2\", \"UVW\", \"FLAG_ROW\"], \n",
    "                       group_cols=[\"SCAN_NUMBER\"], index_cols=[], chunks={\"row\": 1e9}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Averaging Function** (This is what I need to complete)\n",
    "\n",
    "So what is needed is the following variables: \n",
    " * **bl_max_ew**  (Maximum EW distance for the valid rows from uvw)\n",
    " * **rows** (Count number of valid rows, where valid_rows == True)\n",
    " * **bl_max_dist** (Maximum Baseline distance for the valid rows) \n",
    "\n",
    "With the above three variables, it should be possible to calculate baseline_avg_rows (the row size of the compressed data) <br />\n",
    "**bl_max_dist** is calculated from all the uvw values (not just the valid ones)\n",
    "\n",
    "I think the formular for this calculation is the following: <br/>\n",
    " number of valid rows divide by (EW max distance divide by Max baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _averaging_rows(time, ant1, ant2, uvw, flagged_rows, ubl=None):\n",
    "    # TODO(smasoka)\n",
    "    # Understand this\n",
    "    # Need to index passed argument lists,\n",
    "    # as atop contracts over dimensions not present in the output.\n",
    "    # ant1 = ant1[0]\n",
    "    # ant2 = ant2[0]\n",
    "    # uvw = uvw[0][0]\n",
    "    # flagged_rows = flagged_rows[0]\n",
    "\n",
    "    print ant1.shape\n",
    "    print ant2.shape\n",
    "    print uvw.shape\n",
    "    print flagged_rows.shape\n",
    "\n",
    "    # Create empty array container with shape of the unique baselines\n",
    "    baseline_avg_rows = np.empty(ubl.shape[0], dtype=np.int32)\n",
    "    print baseline_avg_rows.shape\n",
    "    print\n",
    "\n",
    "    unflagged = flagged_rows == False\n",
    "    print unflagged\n",
    "    print type(unflagged)\n",
    "\n",
    "    print \"UBL\"\n",
    "    print \"UBL SHAPE \" +str(ubl.shape)\n",
    "    print \"UBL SIZE \" +str(ubl.size)\n",
    "    print\n",
    "\n",
    "    # Foreach baseline\n",
    "    for bl, (a1, a2) in enumerate(ubl):\n",
    "        print \"bl : %s, a1 : %s, a2 : %s\" %(bl, a1, a2)\n",
    "        # Find rows associated with each baseline\n",
    "        # also removing flagged rows\n",
    "        valid_rows = (ant1 == a1) & (ant2 == a2) & unflagged\n",
    "        # depending on the unflagged, valid_rows can be reduced, smaller\n",
    "        print \"VALID_ROWS \" +str(valid_rows.shape)\n",
    "        # print\n",
    "        # Maximum EW distance for each baseline\n",
    "        bl_max_ew = np.abs(uvw[valid_rows, 0]).sum(axis=0)\n",
    "        print \"MAX EW DISTANCE \" +str(bl_max_ew)\n",
    "\n",
    "        # Figure out what the averaged number of rows will be\n",
    "        # I think np.divmod is the way to do this\n",
    "        # baseline_avg_rows[i] = np.divmod(valid_rows)\n",
    "        # Number (count) of valid_rows for this baseline\n",
    "        rows = da.where(valid_rows == True)[0].size\n",
    "        baseline_num_rows.append(rows)\n",
    "        # basically for each ubl (120) array, baseline_avg_rows (120) each\n",
    "        # containing the number of lines/rows (int) : baseline_num_rows\n",
    "\n",
    "        # After the BDA, the row number will change, so I need to calculate\n",
    "        # how they will change so I can create dask array(with chucking)\n",
    "        # to store these new compressed rows. This is where bl_max_ew variable\n",
    "        # comes in. Right?\n",
    "\n",
    "    return baseline_avg_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Array container to hold all the average rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_baseline_avg_rows = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loop that uses dask atop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in xds:\n",
    "    # calls _averaging_rows\n",
    "    # output block pattern (\"bl\",) --> array of baselines\n",
    "    # TIME data (row array)\n",
    "    # ANTENNA1 data (row array)\n",
    "    # ANTENNA2 data (row array)\n",
    "    # UVW data (row array and all columns) ???\n",
    "    # FLAG_ROW data (row array)\n",
    "    # creates a new_axis for the number of baselines\n",
    "    # pass the actual array of unique baselines\n",
    "    # dtype of results\n",
    "    avg_rows = da.core.atop(_averaging_rows, (\"bl\",),\n",
    "                            ds.TIME.data, (\"row\",),\n",
    "                            ds.ANTENNA1.data, (\"row\",),\n",
    "                            ds.ANTENNA2.data, (\"row\",),\n",
    "                            ds.UVW.data, (\"row\", \"(u,v,w)\"),\n",
    "                            ds.FLAG_ROW.data, (\"row\",),\n",
    "                            # Must tell dask about the number of baselines\n",
    "                            new_axes={\"bl\": ubl.shape[0]},\n",
    "                            # Pass through ubl to all instances of\n",
    "                            ubl=ubl,\n",
    "                            dtype=np.int32)\n",
    "\n",
    "    scan_baseline_avg_rows.append(avg_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask compute with argument \"scan_baseline_avg_rows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.compute(scan_baseline_avg_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
